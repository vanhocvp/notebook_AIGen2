{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Batch Normalization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tại sao chúng ta nên sử dụng batch normalization?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Chúng ta thường có 1 công đoạn đó là đơn giản hóa input raw rồi mới ném vào model CNN (VD: X_train /= 255.0 để tính toán tốt hơn) và điều đó cho kết quả tốt hơn. Vậy chẳng phải nếu input of hidden layers của chúng ta cũng được đơn giản hóa thì sẽ cho kết quả tốt hơn sao, và Batch Normalization sẽ giúp chúng ta làm điều tương tự như vậy.\n",
    "* Chúng ta sử dụng gradient để learning model thì gradient không nên quá lớn hoặc quá nhỏ. Batch Norm có thể cải thiện điều này\n",
    "* Các non-linear function (relu, sigmoid, tanh,..) đều có vùng bão hòa. Nếu x của chúng ta nằm trong vùng bão hòa thì sẽ sinh vấn đề sau: với forward việc x trong vùng bão hòa sẽ khiến nhiều ra trị đầu ra sẽ giống nhau mặc dù x khác nhau; với backward, x trong vùng bão hòa sẽ cho garadient = 0 dẫn tới không cập nhật được Weitht và bias. Batch Norm sẽ giúp ta kéo giá trị x về phía 0 tránh lệch về  2 phía để tránh rơi vào vùng bão hòa. Từ đó đảm bảo được rằng activation của chúng ta sẽ không cho kết quả quá lớn hoặc quá nhỏ nên ta có thể cải thiện tốc độ học\n",
    "<img src = 'anh.png'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.layers.BatchNormalization(\n",
    "    axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True,\n",
    "    beta_initializer='zeros', gamma_initializer='ones',\n",
    "    moving_mean_initializer='zeros', moving_variance_initializer='ones',\n",
    "    beta_regularizer=None, gamma_regularizer=None, beta_constraint=None,\n",
    "    gamma_constraint=None, renorm=False, renorm_clipping=None, renorm_momentum=0.99,\n",
    "    fused=None, trainable=True, virtual_batch_size=None, adjustment=None, name=None,\n",
    "    **kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.Stochastic Gradient Descent**\n",
    "\n",
    "Với mỗi epoch thì GD ứng với 1 lần cập nhật parameters, với SGD thì N lần cập  nhật parameter(N- số điểm dữ liệu). Vì SGD mỗi lần chỉ đạo hàm với 1 điểm dữ liệu x và lấy kết quả đạo hàm đó để cập nhật parameter 1 lần.\n",
    "\n",
    "Việc cập nhật liên tục nên SGD có tốc độ hội tụ nhanh hơn rất nhiều GD và khi có điểm dữ liệu mới vào chỉ cần chạy thêm 1 epoch đã cho kết quả tốt.\n",
    "\n",
    "chính vì cập nhật liên tục và đường đi của nghiệm của hàm mất mát biến động thường xuyên. Có thể hạ dần learning rate để cải thiện"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.Mini-batch Gradient Descent**\n",
    "\n",
    "Thay vì mỗi lần đạo hàm sẽ đạo hàm 1 điểm như SGD thì Mini-batch GD sẽ chia N điểm dữ liệu ra thành nhiều batch mỗi batch sẽ có n điểm dữ liệu ( 1 < n <<<< N), và mỗi lần đạo hàm sẽ đạo hàm với 1 batch.\n",
    "\n",
    "Mini-batch sẽ khắc phục nhược điểm của SGD, đường đi sẽ ít giao động hơn, ổn định hơn và sẽ cho hội tụ tốt hơn. Vì vậy mini-batch thường được chọn để train neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.Momemtum**\n",
    "<img src = 'momemtem.png'/>\n",
    "\n",
    "nhìn hình trên ta thấy. nghiệm của GD thông thường sẽ dao động theo 2 chiều x và y, như trong hình thì n dao động lớn theo chiều y và dao động nhỏ theo chiều x => điều đó làm cho thuật toán của chúng ta hội tụ lâu hơn.\n",
    "\n",
    "Chức năng của momemtum là điều chỉnh dao dộng theo các chiều (giảm dao động theo chiều y, và tăng dao động thoe chiều x), nhờ đó sẽ cho ta tốc độ hội tụ nhanh hơn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.RMSprop - Root Mean Square Propogation**\n",
    "\n",
    "Gần giống như momemtum. RMSprop sẽ hạn chế dao động thoe chiều dọc, từ đó ta có thể tăng learning rate => tăng dao động theo chiều ngang => hội tụ nhanh hơn.\n",
    "\n",
    "RMSprop sẽ chọn **learning rate khác nhau** cho mỗi parameter và nó điều chỉnh 1 cách tự động.\n",
    "\n",
    "RMSprop có cách tính toán khác với GD with momemtum:\n",
    "*Với GD with momemtum:\n",
    "    <img src = 'c.png'/>\n",
    "*Với RMSprop:\n",
    "    <img src = 'c1.png'/>\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.Adam - Adaptive Moment Optimization**\n",
    "\n",
    "Adam là thuật toán giúp tính toán learning rate thích ứng cho mỗi parameter. Nó được kết hợp bởi cả RMSprop và SGD with momemtum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet-5 (1998)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'Lenet5.png'/>\n",
    "<img src = 'LeNEt_Summary_Table.jpg'/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LeNet là 1 mạng CNN ra đời bởi LeCun.\n",
    "\n",
    "Mạng gồm 2 Convolutional layer  và 3 FC layer thế nên nó mô hình này có thêm hậu tố là \"5\"\n",
    "\n",
    "- Activation func: tanh nên không tránh được vanishing gradient\n",
    "\n",
    "- Architecture này phù hợp với các bài toán cần dữ liệu nhỏ, các bức ảnh xám,... Để xử lý các hình ảnh có độ phân giải cao hơn đòi hỏi nhiều ConV hơn và lớn hơn. Đây là mặt hạn chế của LeNet-5\n",
    "\n",
    "- LeNet đã trở thành khuôn mẫu cho các Architecture sau này:xếp Conv và Pooling đi liền với nhau và xếp  nhiều cặp Conv-Pooling cạnh nhau, kết thúc bằng 1 hay nhiều FC layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlexNet(2012)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'Anh/AlexNet.png'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AlexNet giống như LeNet-5 nhưng sâu hơn. Sử dụng 5 Conv layer 11x11 5x5 3x3 và 3 FC layer \n",
    "\n",
    "max pooling(3x3), dropout, data augmentation, ReLU activations, SGD with momentum\n",
    "\n",
    "- input của AlexNet là 256x256x3 nhưng nhóm tác giả chỉ sử dụng 1 phần của bức ảnh là 227*227*3 để làm đầu vào cho neural network\n",
    "- AlexNet là architecture đầu tiên sử dụng ReLU làm activation function\n",
    "- Nhóm nghiên cứu của AlexNet đã nghiên cứu về overfiting và tìm cách để giảm thiểu nó : data augmentation, dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG-16 (2014)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'Anh/VGG.png'/>\n",
    "VGG là viết tắt của Visual Geometry Group - tên group đã cho ra đời Architecture này.\n",
    "\n",
    "\n",
    "Nhóm nghiên cứu này đã nghiên cứu về ảnh hưởng của độ sâu của CNN tới độ chính xác của nhận diện ảnh trong quy mô lớn, và họ đã công bố 2 mô hình tốt nhất của họ là VGG-16 và VGG-19\n",
    "\n",
    "Giống như LeNet, hậu tố 16 ở đây tức mô hình có 16 lớp, bao gồm : 13 conv layer và 3 FC layer\n",
    "\n",
    "Kế thừa từ AlexNet VGG sử  dụng reLu cho các tất cả conv layer và fc layer, chỉ có fc layer cuối cùng dùng softmax.\n",
    "\n",
    "Khác với việc dùng các filter lớn 11x11 5x5 như AlexNet, VGG sử dụng các filter có kích thước nhỏ 3x3\n",
    "\n",
    "VGG có 2 vấn đề hạn chế lớn :\n",
    "\n",
    "- Training chậm vì mô hình rất sâu\n",
    "- Số lượng parameters lớn: 138 triệu -> model chiếm tới 530 MB -> Một thử thách cho tính toán\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GoogLeNet / inception v1(2014)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'Anh/GoogleNet.png'/>\n",
    "GoogLeNet giành chiến thắng trong cuộc thi ILSVRC-2014 với kết qủa. Nó đã có cái thiện đáng kể so với AlexNet(2012) và ZFNET(2013) và có error rate thấp hơn VGG(2014)\n",
    "\n",
    "Nhìn vào tên của architecture là biết nó ra đời bởi google. Hơn thế nữa, có sự khác lạ là chữ \"L\" viết hoa, và tạo thành hậu tố \"LeNet\", đây là chủ ý của gg để vinh danh Yan LeCun-người cho ra đời LeNet.\n",
    "\n",
    "GoogLeNet lấy cảm hứng từ LeNet nhưng triển khai 1 yếu tố mới đó là inception model, mà bởi vậy nên mạng này còn có tên gọi khác là inception\n",
    "\n",
    "Khác hoàn toàn với AlexNET, ZFNET, VGG, GGNet. Nó chứa Conv 1x1 ở giữa mạng và sử dụng global average pooling ở cuối mạng thay thế cho FCL. NGười ta còn có gọi khác cho 2 kĩ thuật này là \"Network in Network\" - NIN\n",
    "\n",
    "- 1x1 Convolution: Nó giúp giảm kích thước mô hình và còn giảm được cả overfiting. Ví dụ bên dưới cho thấy tác dụng giảm kích thước mô hình của 1x1 Conv\n",
    "\n",
    "<img src = 'Anh/1_s6_8m_0EpwrzZPunRGgFCQ.png'/>\n",
    "\n",
    "Number of operations = (14×14×48)×(5×5×480) = 112.9M\n",
    "\n",
    "<img src = 'Anh/1_SJDJyBGM__wRX9wJYIKv8w.png'/>\n",
    "\n",
    "Number of operations for 1×1 = (14×14×16)×(1×1×480) = 1.5M\n",
    "\n",
    "Number of operations for 5×5 = (14×14×48)×(5×5×16) = 3.8M\n",
    "\n",
    "Total number of operations = 1.5M + 3.8M = 5.3M << 112.9M - nhỏ hơn 20 lần, giúp cho việc tính toán bớt nặng nhọc hơn.\n",
    "\n",
    "<img src = 'Anh/1_53uKkbeyzJcdo8PE5TQqqw.png'/>\n",
    "<img src = 'Anh/InceptionModules.png'/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Global Average Pooling:\n",
    "<img src = 'Anh/1_53uKkbeyzJcdo8PE5TQqqw.pngavg.png'/>\n",
    "Thay vì là FCL ở cuối model như các architectures trước, inception sử dụng global average Pooling ở gần cuối model: Sử dụng average chuyển các feature map 7x7 thành 1x1. Cách này sẽ giúp giảm số lượng phép tính so với FCL nhưng vẫn giữ được các feature vì mạng của chúng ta đã rất sâu rồi và nó còn giúp giảm overfiting.\n",
    "\n",
    "- Cấu trúc GoogLeNet:\n",
    "<img src = 'Anh/all.jpeg'/>\n",
    "\n",
    "Mạng gồm 22 layer.\n",
    "\n",
    "<img src = 'Anh/parametes.png'/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Auxiliary Classifiers for Training**\n",
    "\n",
    "Như chúng ta đã thấy trong sơ đồ thiết kế của GoogLeNet có 2 nhánh tại 4a và 4d. 2 nhánh này là 2 nhánh phụ trợ cho model\n",
    "\n",
    "Model của chúng ta rất sâu nên 1 vấn đề dễ phát sinh là **vanishing gradients**. Càng sâu về phía trong mạng thì gradient càng mang ít thông tin để cập nhất weight. Không chỉ các feature ở cuối model mới có thể phân loại mà các feature ở giữa model cũng có thể, thậm chí nó có thể đáng tin cậy hơn vì ở đó gradient mang nhiều thông tin để update weight hơn. Chính vì vậy mà họ đã thêm 2 nhánh vào 4a và 4d (1/3 và 2/3 của inceptions) để  tính loss, và loss tổng sẽ là tổng của 3 loss này(loss của Auxiliary layer lấy 0.3 tức nhân nhân với 0.3).\n",
    "\n",
    "5×5 Average Pooling (Stride 3)\n",
    "\n",
    "1×1 Conv (128 filters)\n",
    "\n",
    "1024 FC\n",
    "\n",
    "1000 FC\n",
    "\n",
    "Softmax\n",
    "\n",
    "Và nó chỉ sử dung trong quá trình training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet (2015)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "CNN truyền thống là việc đặt các conv và pooling cạnh nhau, và cải tiến nó đi sâu hơn, và đều đã cho những kết quả tốt như VGG Inception, nhưng liệu có phải càng sâu thì sẽ càng tốt và liệu có giới hạn nào cho độ sâu này khoong?\n",
    "<img src = 'https://miro.medium.com/max/1224/0*fRYbrOU_YhS6oMf-'/>\n",
    "\n",
    "Họ thử nghiệm và so sánh giữa CNN 20 layer và CNN 56 layer. Và kết quả là model 56 layer cho kết quả kém hơn model 20 layer. Sự thất bại này có thể do overfiting, vanishing gradent,... Và rút ra rằng, 1 model CNN hoạt động hoạt động tốt với 16-30 layer.\n",
    "\n",
    "Để giải quyết vấn đề làm sao để có thể đi sâu hơn, Residual block đã ra đời.\n",
    "<img src = 'https://miro.medium.com/max/2000/1*zbDxCB-0QDAc4oUGVtg3xw.png'/>\n",
    "\n",
    "ResNet có nhiều model tùy thuộc vào số lượng layer: 18, 34, 50, 101, 152\n",
    "\n",
    "- sử dụng filter 3x3\n",
    "\n",
    "- đi đầu trong việc sử dụng batch normalisation.\n",
    "\n",
    "- Global average pooling layer , FLC và softmax ở cuối \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Residual blocks \n",
    "<img src = 'https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/image_folder_5/residual_bottleneck.png'/>\n",
    "\n",
    "Với H(x) là giá trị dự đoán, F(x) là giá trị thật (nhãn). Thay vì tính x -> y bằng H(x) như thông thường, chúng ta sẽ tính H(x) = F(x) + x\n",
    "\n",
    "F(x) = X->weight1-> ReLU -> weight2\n",
    "\n",
    "H(x) = F(x) + x -> ReLU\n",
    "\n",
    "- Có 2 loại residual conection:\n",
    "+ Nếu input và output có cùng dim: Ta có thể sử dụng trực tiếp indentity\n",
    "<img src = 'https://miro.medium.com/max/968/1*37brTipLpo6naVYHiXMbsg.png'/>\n",
    "\n",
    "+ Nếu input và output khác dim, người ta sẽ sử dụng conv 1x1 để giảm chiều nó đi\n",
    "<img src = 'https://miro.medium.com/max/974/1*07wrOB82Ktl3uWhY0GWE7A.png'/>\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MobieNet\n",
    "\n",
    "MobieNet ra đời bởi google, điểm nổi bật của nó so với các architecture trước đây là nó sử dụng Depthwise Separable Convolution để giảm kích thước model và giảm độ phức tạp tính toasn( ít phép tính nhân và cộng hơn).\n",
    "\n",
    "- Depthwise Separable Convolution:\n",
    "\n",
    "Cấu tạo gồm depthwise convolution theo sau là pointwise\n",
    "\n",
    "- depthwise conv: khác với cov thông thường,  mỗi 1 input channel sẽ có 1 filter riêng\n",
    "- pointwise: là conv 1x1\n",
    "\n",
    "<img src = 'https://www.mdpi.com/electronics/electronics-08-00825/article_deploy/html/images/electronics-08-00825-g006.png'/>\n",
    "\n",
    "<img src = 'https://www.phamduytung.com/post_image/depthwise_separable_convolution.png'/>\n",
    "\n",
    "sau khi đi qua các filter các input channel sẽ gộp lại với nhau. Vậy nên depthwise conv sẽ cho output cùng size với input\n",
    "\n",
    "- Giảm chi phí tính toán :\n",
    "    + M: số lượng input channel, N: số lượng output chanel\n",
    "    \n",
    "    + Dk: kích thước kernel size\n",
    "    \n",
    "    + Df: Kích thước input, hay feature map( như ImageNet là 224)\n",
    "    \n",
    "    Chi phí tính toán của Conv thông thường là :\n",
    "    $$D_k \\cdot D_k \\cdot M \\cdot N \\cdot D_f \\cdot D_f$$\n",
    "    Chi phí tính toán của Depthwise Separable Conv:\n",
    "    $$D_k \\cdot D_k \\cdot M \\cdot D_f \\cdot D_f + M \\cdot N \\cdot D_f \\cdot D_f$$\n",
    "    Chi phí tính toán tiết kiệm được là:\n",
    "    $$\\frac{D_k \\cdot D_k \\cdot M \\cdot D_f \\cdot D_f + M \\cdot N \\dot D_f \\cdot D_f}{D_k \\cdot D_k \\cdot M \\cdot N \\cdot D_f \\cdot D_f} = \\frac{1}{N} + \\frac{1}{D^2_k}$$\n",
    "    \n",
    "<img src = 'https://www.phamduytung.com/post_image/standard_convolution_vs_depthwise_seperable_convolution.png'/>\n",
    "\n",
    "Sau mỗi Depthwise Separable Convolution sẽ là batchnorm và Relu\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Để mô hình gọn nhẹ hơn nhóm nghiên cứu đã sử dụng 2 thông số là $\\alpha$ và $\\rho$\n",
    "- $\\alpha$ dùng để điều chỉnh số channel M và N. $\\alpha$ trong khoảng [0,1]\n",
    "<img src = 'https://www.phamduytung.com/post_image/mobilenet_alpha_changes.png'/>\n",
    "việc số lượng phép tính và số lượng thông số giảm đồng nghĩa với với chất lượng giảm\n",
    "\n",
    "- $\\rho$ dùng để điều chỉnh độ phân giải của ảnh. chỉ giảm số lượng tính toán chứ không giảm thông số"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
